{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 불러오기"
      ],
      "metadata": {
        "id": "CcQiJdnBPQ5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "정상 - 하나로\n",
        "결막염\n",
        "백내장"
      ],
      "metadata": {
        "id": "yrs-a_AbMoh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iGj6klphiAl_",
        "outputId": "e764b6bf-9fd0-420c-97ce-3c6cce2649d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m2RboTsTNxpt"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import splitfolders\n",
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nam_classes = 10\n",
        "input_shape = (400, 400, 3)\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "epoch_num = 30\n",
        "num_heads = 8\n",
        "trans_num = 8\n",
        "img_patch_size = 4\n",
        "p_i_num=int(32*32/4/4)\n",
        "proj_num = 32\n",
        "class_num = 10\n"
      ],
      "metadata": {
        "id": "tY5WJEg_faTA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data unzip"
      ],
      "metadata": {
        "id": "T8Zghjm_PT3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q \"/content/drive/MyDrive/CV_project/data/안구질환/개_질환_최종.zip\"\n"
      ],
      "metadata": {
        "id": "0Ds69P_2O1ZZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitfolders.ratio('/content/개', output='output_dir', ratio=(0.8, 0.1, 0.1))  # train/val/test = 8:1:1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhfwjgQrh76S",
        "outputId": "dcc6af3c-614b-4956-bf79-836e78e9acea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 68875 files [01:41, 680.84 files/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 인코딩 값 정의\n",
        "position_input = [range(64) for i in range(50000)]\n",
        "position_input = np.array(position_input)\n",
        "position_input = np.reshape(position_input, (50000,64,1))\n",
        "\n",
        "# 모델 정의\n",
        "i = tf.keras.Input(shape=input_shape)\n",
        "p_i = tf.keras.Input(shape=(p_i_num,1))\n",
        "out_patch = tf.image.extract_patches(images=i,\n",
        "                                     sizes=[1, img_patch_size, img_patch_size, 1],\n",
        "                                     strides=[1, img_patch_size, img_patch_size, 1],\n",
        "                                     rates=[1, 1, 1, 1],\n",
        "                                     padding=\"VALID\")\n",
        "\n",
        "out = tf.keras.layers.Reshape([-1, img_patch_size * img_patch_size * 3])(out_patch)\n",
        "p_out = tf.keras.layers.Embedding(p_i_num, proj_num)(p_i)\n",
        "out = tf.keras.layers.Dense(pro_j_num)(out)\n",
        "out = tf.keras.layers.Add()([out, p_out])\n",
        "\n",
        "for _ in range(trans_num):\n",
        "    out = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out)\n",
        "    a_out = tf.keras.layers.MultiHeadAttention(num_heads=num_heads,\n",
        "                                               key_dim=proj_num,\n",
        "                                               dropout=0.1)(out_1, out_1)\n"
      ],
      "metadata": {
        "id": "ksvGh8jFhfQP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}