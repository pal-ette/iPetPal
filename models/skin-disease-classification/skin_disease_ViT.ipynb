{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "fBW67ETv856c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "W4jk0LSB-bxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "2jb-2QY79jtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "ld7mLLZe87-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "img_size = 224\n",
        "\n",
        "data_dir = ''"
      ],
      "metadata": {
        "id": "pvGszkTT-pnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import (\n",
        "    CenterCrop,\n",
        "    Compose,\n",
        "    Normalize,\n",
        "    RandomHorizontalFlip,\n",
        "    RandomResizedCrop,\n",
        "    Resize,\n",
        "    ToTensor,\n",
        ")\n",
        "\n",
        "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
        "\n",
        "transforms = Compose(\n",
        "        [\n",
        "            Resize(img_size),\n",
        "            ToTensor(),\n",
        "            normalize,\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def preprocess(example_batch):\n",
        "\n",
        "    example_batch[\"pixel_values\"] = [\n",
        "        transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
        "    ]\n",
        "    return example_batch"
      ],
      "metadata": {
        "id": "urC6slLh9NAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform)\n",
        "valid_dataset = datasets.ImageFolder(os.path.join(data_dir, 'valid'), transform)\n",
        "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform)"
      ],
      "metadata": {
        "id": "JwcEPNa3_o4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = train_dataset.features[\"label\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = i\n",
        "    id2label[i] = label\n",
        "\n",
        "id2label[0]"
      ],
      "metadata": {
        "id": "SU6h8As_Coyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=4)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=4)"
      ],
      "metadata": {
        "id": "bl9td9Hr-CEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pre-trained Model"
      ],
      "metadata": {
        "id": "oU6lfIkt891b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "feature_extractor"
      ],
      "metadata": {
        "id": "tWeHzC0h8wAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhKOvhxT8N4I"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"google/vit-base-patch16-224\",\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes = True,\n",
        ").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "img_size = 224"
      ],
      "metadata": {
        "id": "xBB6Aadz9G0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "2Nu9xk8X8_xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vit\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-skin-disease\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=10,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to='none'\n",
        ")"
      ],
      "metadata": {
        "id": "nogREeyjDCxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
      ],
      "metadata": {
        "id": "yXZCYdr8DMd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(examples):\n",
        "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
        "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "jr2284jLDRHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=val_ds,\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=collate_fn,\n",
        ")"
      ],
      "metadata": {
        "id": "1ONGvqVhDT4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = trainer.train()\n",
        "trainer.save_model()\n",
        "trainer.log_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_metrics(\"train\", train_results.metrics)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "m-q7n2qdENtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "# some nice to haves:\n",
        "trainer.log_metrics(\"eval\", metrics)\n",
        "trainer.save_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "id": "-vHo3wiVERE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "OxCAhjl8ET2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
        "\n",
        "repo_name = \"/content/../vit-finetuned-skin-disease\"\n",
        "\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(repo_name,local_files_only=True)\n",
        "model = AutoModelForImageClassification.from_pretrained(repo_name,local_files_only=True)"
      ],
      "metadata": {
        "id": "jvYxVOSCEVDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = dataset[\"test\"][-1]\n",
        "image = example['image']\n",
        "image"
      ],
      "metadata": {
        "id": "Fo1vNlNqEhTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = feature_extractor(image.convert(\"RGB\"), return_tensors=\"pt\")\n",
        "print(encoding.pixel_values.shape)"
      ],
      "metadata": {
        "id": "P-h3s4q4EbNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# forward pass\n",
        "with torch.no_grad():\n",
        "  outputs = model(**encoding)\n",
        "  logits = outputs.logits"
      ],
      "metadata": {
        "id": "7sQrToYfEc8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "S9XKfbB8EkIF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}